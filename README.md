# Artificial_Intelligence

**COURSE DESCRIPTION**

Knowledge representation and reasoning; Theory and advanced programming techniques; Topics selected from areas of expert systems, natural language processing, image understanding, machine learning, games, and robotics.



TENTATIVE SCHEDULE:
  AI: Concepts and history  
  Solving problems by searching  
o Uninformed search  
o Informed search  
o Constraint satisfaction problems  
  Games  
o The minimax principle  
o Modern game-playing systems  
o Game theory  
  Planning  
  Probabilistic reasoning  
o Basic probability concepts  
o Bayesian inference o Naive Bayes models o Bayesian networks  
   Machine learning  
o Supervised vs. unsupervised learning o Decision trees  
o Nearest neighbor classifiers  
o Neural networks  
o Deep learning  
  Reinforcement learning  
o Markov decision processes  
o Q-learning  
o Deep reinforcement learning  
   Applications of AI  
o Robotics  
o Computer vision  
o Natural language processing  

### Assignment 1 8-Puzzle Programming. Implementation of function "Iterative_deeping_DFS", aStarMisplacedTile and  aStarMangattanDistance.

### Assignment 2 22queen. Implementation of Backtracking

### Assignment 3 Tic-Tac_Toe.    Implementation of Decision Tree (MiniMax)

### Assignment 4 Value Iteration  In a 10x10 grid world, do 30 times value iteration:  
A 10x10 grid world  
2. Noise=0.15, discount = 0.91  
3. There are four actions west, east, north, south. The actions are all “north” in the initial policy. After each iteration, the actions in the policy need to be updated to the direction that points to the adjacent grid that has the highest value.  
4. There are two terminal grids, one has reward +2 and the other one is -2. The location should be given set by using the given variables at the beginning.  
5. One grid is occupied by a stone whose location is specified by the giving variables at the beginning.
6. The grid world is surrounded by walls.  
7. The agent will stay at the same position if it moves towards a stone or a wall.
8. The output should contain the number of iteration statuses of the grid world in the following format. The following is one status. STONE stands for a stone. 0.00 stands for the current value. The actions of the current policy are indicated as w, e, n, and s.

![course](https://github.com/YanZiQinKevin/Artificial_Intelligence/blob/master/pdf/IMG_2325.PNG)
